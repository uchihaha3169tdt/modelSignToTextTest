"# ğŸ¤˜ YouTube Sign Language Generation

Text-to-Sign-Language motion generation using diffusion models, customized for Vietnamese sign language from YouTube videos.

## ğŸ“‹ Overview

This repository is adapted from [Sign-Diffusion-Model](https://github.com/kha-kim-thuy/Sign-Diffusion-Model) to work with sign language data extracted from YouTube videos using MediaPipe and OCR.

**Key Features:**
- âœ… Support for OpenPose keypoints (50 joints, 150 dimensions)
- âœ… Vietnamese and English text captions
- âœ… Space-Time U-Net with Scale-Aware Modulation (SAM-STUNet)
- âœ… Diffusion-based motion generation

## ğŸ”§ Installation

```bash
# Clone repository
git clone https://github.com/uchihaha3169tdt/modelSignToTextTest.git
cd modelSignToTextTest

# Setup environment
bash scripts/setup.sh
```

## ğŸ“ Dataset Structure

Place your processed YouTube Sign dataset in:

```
dataset/YOUTUBE_SIGN/
â”œâ”€â”€ new_joints/         # .npy motion files [T, 150]
â”œâ”€â”€ texts/              # .txt caption files
â”œâ”€â”€ train.txt           # training split
â”œâ”€â”€ val.txt             # validation split
â”œâ”€â”€ test.txt            # test split
â””â”€â”€ all.txt             # all samples
```

**Motion format:** OpenPose keypoints with 50 joints Ã— 3 coordinates = 150 dimensions per frame.

**Text format:** Each `.txt` file contains lines in format:
```
caption#token1/POS token2/POS ...#0.0#0.0
```

## ğŸš€ Training

### 1. Prepare data

```bash
bash scripts/prepare_data.sh
```

This will calculate Mean.npy and Std.npy statistics for normalization.

### 2. Download GloVe embeddings

```bash
bash prepare/download_glove.sh
```

### 3. Train the model

```bash
bash scripts/train_youtube_sign.sh
```

Or manually:

```bash
python -m train.train_mdm \
    --arch sam_stunet \
    --lr 1e-4 \
    --overwrite \
    --save_interval 1000 \
    --num_steps 400000 \
    --dataset youtube_sign \
    --save_dir ./save/youtube_sign_model \
    --batch_size 64 \
    --diffusion_steps 1000 \
    --device 0
```

## ğŸ“Š Model Architecture

The main model is **SAM-STUNet** (Space-Time U-Net with Scale-Aware Modulation):
- Encoder-decoder U-Net architecture for temporal modeling
- Scale-aware modulation for multi-scale feature fusion
- Classifier-free guidance for text conditioning
- Multilingual CLIP (clip-ViT-B-32-multilingual-v1) for text encoding

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ data_loaders/
â”‚   â”œâ”€â”€ get_data.py          # Dataset loader factory (supports youtube_sign)
â”‚   â”œâ”€â”€ tensors.py           # Tensor utilities and collate functions
â”‚   â””â”€â”€ humanml/
â”‚       â”œâ”€â”€ data/dataset.py  # Dataset classes including YouTubeSign
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ get_opt.py   # Dataset configuration (includes youtube_sign)
â”‚           â”œâ”€â”€ word_vectorizer.py
â”‚           â””â”€â”€ metrics.py
â”œâ”€â”€ diffusion/               # Diffusion model utilities
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ mdm.py               # MDM transformer model
â”‚   â””â”€â”€ sam_stunet.py        # SAM-STUNet architecture (main model)
â”œâ”€â”€ train/                   # Training scripts
â”œâ”€â”€ sample/generate.py       # Generation/sampling script
â”œâ”€â”€ utils/                   # Utility functions
â”œâ”€â”€ prepare/
â”‚   â”œâ”€â”€ calculate_stats.py   # Calculate dataset statistics
â”‚   â””â”€â”€ download_glove.sh    # Download GloVe embeddings
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ youtube_sign_opt.txt # Dataset configuration
â””â”€â”€ scripts/
    â”œâ”€â”€ setup.sh             # Environment setup
    â”œâ”€â”€ prepare_data.sh      # Data preparation
    â””â”€â”€ train_youtube_sign.sh # Training script
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Original [Sign-Diffusion-Model](https://github.com/kha-kim-thuy/Sign-Diffusion-Model) by kha-kim-thuy
- [MDM: Human Motion Diffusion Model](https://github.com/GuyTevet/motion-diffusion-model)
- [text-to-motion](https://github.com/EricGuo5513/text-to-motion)
" 
